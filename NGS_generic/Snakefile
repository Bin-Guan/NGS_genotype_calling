from os.path import join
import sys

#configfile: "/home/mcgaugheyd/git/NGS_genotype_calling/NGS_generic_workflow/config.yaml"

def chr_GVCF_to_single_GVCF(wildcards):
	# creates the filenames for the chr level GVCFs to use to concatenate to a single file
	# ensures that input GVCF chrs are provided in order (same as CHRS) below
	sample = str(wildcards)
	sample_by_chr = []
	for chrom in CHRS:
		sample_by_chr.append('gvcfs/chr_split/' + sample + '/' + sample + '__' + str(chrom) + '.g.vcf.gz')
	return(sample_by_chr)


def chr_bam_to_single_bam(wildcards):
	# creates the filenames for the chr level bams to use to concatenate to a single file
	sample = str(wildcards)
	sample_by_chr = []
	for chrom in CHRS:
		sample_by_chr.append('bam/chr_split/' + sample + '/' + sample + '__' + str(chrom) + '.realigned.CleanSam.sorted.markDup.gatk_realigner.recalibrated.bam')
	return(sample_by_chr)

def rg(wildcards):
	# returns the read group given in config.yaml's read_group for a sample
	# by index. config['sample'] and config['read_groups'] should be given
	# as matched lists
	sample = str(wildcards)
	all_path_samples = config['samples']
	all_samples = [s.split('/')[-1] for s in all_path_samples]
	rgs = config['read_groups']
	rg_out = rgs[all_samples.index(sample)]
	return(rg_out)


#(SAMPLES, FILE_ENDINGS) = glob_wildcards(join('{sample}_[1|2].{file_ending}'))
CHRS=["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","X","Y","MT_contigs"]
MT_CONTIGS="MT GL000207.1 GL000226.1 GL000229.1 GL000231.1 GL000210.1 GL000239.1 GL000235.1 GL000201.1 GL000247.1 GL000245.1 GL000197.1 GL000203.1 GL000246.1 GL000249.1 GL000196.1 GL000248.1 GL000244.1 GL000238.1 GL000202.1 GL000234.1 GL000232.1 GL000206.1 GL000240.1 GL000236.1 GL000241.1 GL000243.1 GL000242.1 GL000230.1 GL000237.1 GL000233.1 GL000204.1 GL000198.1 GL000208.1 GL000191.1 GL000227.1 GL000228.1 GL000214.1 GL000221.1 GL000209.1 GL000218.1 GL000220.1 GL000213.1 GL000211.1 GL000199.1 GL000217.1 GL000216.1 GL000215.1 GL000205.1 GL000219.1 GL000224.1 GL000223.1 GL000195.1 GL000212.1 GL000222.1 GL000200.1 GL000193.1 GL000194.1 GL000225.1 GL000192.1 NC_007605"

PATH_SAMPLES = config['samples']
# strip out file paths
SAMPLES = [s.split('/')[-1] for s in PATH_SAMPLES]
# grab the file path ahead of sample name
# assume all files have same path
PATH = ['/'.join(s.split('/')[:-1]) for s in PATH_SAMPLES][0]
# if path is blank, then make a period for the file will be ./file below
if PATH != '':
	PATH = PATH + '/'

wildcard_constraints:
	sample='|'.join(SAMPLES)

rule all:
	input: 
	#	expand('gvcfs/chr_split/{sample}/{sample}__{chr}.g.vcf.gz', sample=SAMPLES, chr=CHRS)
		expand('gvcfs/{sample}.g.vcf.gz', sample=SAMPLES),
		expand('bam/{sample}.realigned.recalibrated.bam', sample=SAMPLES),
		'GATK_metrics/multiqc_report',
		'fastqc/multiqc_report'

rule bam_to_fastq:
	input:
		PATH + '{sample}.bam'
	output:
		forward = temp(PATH  + '{sample}_' + config['fastq_ending_for']),
		reverse = temp(PATH  + '{sample}_' + config['fastq_ending_rev'])
	threads: 2
	shell:
		"""
		module load {config[samtools_version]}
		mkdir -p /scratch/mcgaugheyd/$SLURM_JOB_ID/
		export REF_CACHE=/scratch/mcgaugheyd/$SLURM_JOB_ID/hts-refcache
		samtools collate -uOn 128 {wildcards.sample}.bam /scratch/mcgaugheyd/$SLURM_JOB_ID/TMP_{wildcards.sample} | \
			samtools fastq - -1 {output.forward} -2 {output.reverse}
		"""

rule align:
	input:
		forward = PATH  + '{sample}_' + config['fastq_ending_for'],
		reverse = PATH  + '{sample}_' + config['fastq_ending_rev']
	output:
		temp('bam/{sample}.realigned.bam')
	params:
		read_group = rg
	threads: 32
	shell:
		"""	
		module load {config[bwa_version]}; 
		module load {config[samtools_version]}; 
		bwa mem -M -t {threads} -B 4 -O 6 -E 1 -M -R {params.read_group} \
			{config[bwa_genome]} \
			<(zcat {input.forward}) <(zcat {input.reverse}) | samtools view -1 - \
		> {output} 
		"""

rule sort:
	input:
		'bam/{sample}.realigned.bam'
	output:
		temp('bam/{sample}.realigned.s.bam')
	threads: 8 
	shell:
		"""
		export REF_CACHE=/scratch/$SLURM_JOB_ID/hts-refcache
		module load {config[samtools_version]}
		samtools sort {input} -@ {threads} -T /scratch/$SLURM_JOB_ID -o {output}
		"""

rule build_index:
	input:
		'bam/{sample}.realigned.s.bam'
	output:
		temp('bam/{sample}.realigned.s.bam.bai')
	threads: 2
	shell:
		"""
		export REF_CACHE=/lscratch/$SLURM_JOB_ID/hts-refcache
		module load {config[samtools_version]}
		samtools index {input} {output}
		"""

rule fastqc:
	input:
		'bam/{sample}.realigned.bam'
	output:
		'fastqc/{sample}'
	threads: 8
	shell:
		"""
		module load fastqc
		mkdir -p fastqc 
		mkdir fastqc/{wildcards.sample}
		fastqc -t {threads} -o {output} {input}
		"""

rule split_bam_by_chr:
	input:
		bam = 'bam/{sample}.realigned.s.bam',
		bai = 'bam/{sample}.realigned.s.bam.bai'
	output:
		temp('bam/chr_split/{sample}/{sample}__{chr}.realigned.bam')
	threads: 2
	shell:
		"""
		module load {config[samtools_version]}
		if [[ {wildcards.chr} != "MT_contigs" ]]; then
			samtools view -bh {input.bam} {wildcards.chr} > {output}
		else
			samtools view -bh {input.bam} {MT_CONTIGS}  > {output}
		fi 
		"""

rule picard_clean_sam:
# "Soft-clipping beyond-end-of-reference alignments and setting MAPQ to 0 for unmapped reads"
	input:
		'bam/chr_split/{sample}/{sample}__{chr}.realigned.bam'
	output:
		temp('bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.bam')
	threads: 2
	shell:
		"""
		module load {config[picard_version]}
		java -Xmx60g -XX:+UseG1GC -XX:ParallelGCThreads={threads} -jar $PICARD_JAR \
			CleanSam \
			TMP_DIR=/lscratch/$SLURM_JOB_ID \
			INPUT={input} \
			OUTPUT={output}
		"""

rule picard_fix_mate_information:
# "Verify mate-pair information between mates and fix if needed."
# also coord sorts
	input:
		'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.bam'
	output:
		temp('bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.bam')
	threads: 2
	shell:
		"""
		module load {config[picard_version]}
		java -Xmx60g -XX:+UseG1GC -XX:ParallelGCThreads={threads} -jar $PICARD_JAR \
		FixMateInformation \
			SORT_ORDER=coordinate \
			INPUT={input} \
			OUTPUT={output}
		"""

rule picard_mark_dups:
# Mark duplicate reads
	input:
		'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.bam'
	output:
		bam = ('bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.bam'),
		metrics = 'GATK_metrics/{sample}__{chr}.markDup.metrics'
	threads: 2
	shell:
		"""
		module load {config[picard_version]}
		java -Xmx60g -XX:+UseG1GC -XX:ParallelGCThreads={threads} -jar $PICARD_JAR \
			MarkDuplicates \
			INPUT={input} \
			OUTPUT={output.bam} \
			METRICS_FILE={output.metrics}
		"""

rule picard_bam_index:
# Build bam index
	input:
		'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.bam'
	output:
		temp('bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.bam.bai')
	threads: 2
	shell:
		"""
		module load {config[picard_version]}
		java -Xmx60g -XX:+UseG1GC -XX:ParallelGCThreads={threads} -jar $PICARD_JAR \
		BuildBamIndex \
			INPUT={input} \
			OUTPUT={output}
		"""

rule gatk_realigner_target:
# identify regions which need realignment
	input:
		bam = 'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.bam',
		bai = 'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.bam.bai'
	output:
		temp('bam/chr_split/{sample}/{sample}__{chr}.forIndexRealigner.intervals')
	threads: 2
	shell:
		"""
		module load {config[gatk_version]}
		GATK -p {threads} -m 8g RealignerTargetCreator  \
			-R {config[ref_genome]}  \
			-I {input.bam} \
			--known {config[1000g_indels]} \
			--known {config[mills_gold_indels]} \
			-o {output}
		"""

rule gatk_indel_realigner:
# realigns indels to improve quality
	input:
		bam = 'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.bam',
		bai = 'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.bam.bai',
		targets = 'bam/chr_split/{sample}/{sample}__{chr}.forIndexRealigner.intervals'
	output:
		temp('bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.gatk_realigner.bam')
	threads: 2
	shell:
		"""
		module load {config[gatk_version]}
		GATK -p {threads} -m 8g IndelRealigner \
			-R {config[ref_genome]} \
			-I {input.bam} \
			--knownAlleles {config[1000g_indels]} \
			--knownAlleles {config[mills_gold_indels]} \
			-targetIntervals {input.targets} \
			-o {output} 
		"""

rule gatk_base_recalibrator:
# recalculate base quality scores
	input:
		'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.gatk_realigner.bam'
	output:
		'GATK_metrics/{sample}__{chr}.recal_data.table1'
	threads: 2
	shell:
		"""
		module load {config[gatk_version]}
		GATK -p {threads} -m 15g BaseRecalibrator  \
			-R {config[ref_genome]} \
			-I {input} \
			--knownSites {config[1000g_indels]} \
			--knownSites {config[mills_gold_indels]} \
			--knownSites {config[dbsnp_var]} \
			-o {output}
		"""

rule gatk_print_reads:
# print out new bam with recalibrated scoring
	input:
		bam = 'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.gatk_realigner.bam',
		bqsr = 'GATK_metrics/{sample}__{chr}.recal_data.table1'
	output:
		temp('bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.gatk_realigner.recalibrated.bam')
	threads: 2
	shell:
		"""
		module load {config[gatk_version]}
		GATK -p {threads} -m 15g PrintReads \
			-R {config[ref_genome]} \
			-I {input.bam} \
			-BQSR {input.bqsr} \
			-o {output}
		"""

rule gatk_base_recalibrator2:
# recalibrate again
	input:
		bam = 'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.gatk_realigner.bam',
		bqsr = 'GATK_metrics/{sample}__{chr}.recal_data.table1'
	output:
		'GATK_metrics/{sample}__{chr}.recal_data.table2'
	threads: 2
	shell:
		"""
		module load {config[gatk_version]}
		GATK -p {threads} -m 15g BaseRecalibrator  \
			-R {config[ref_genome]} \
			-I {input.bam} \
			--knownSites {config[1000g_indels]} \
			--knownSites {config[mills_gold_indels]} \
			--knownSites {config[dbsnp_var]} \
			-BQSR {input.bqsr} \
			-o {output}
			"""

rule gatk_analyze_covariates:
	input:
		one = 'GATK_metrics/{sample}__{chr}.recal_data.table1',
		two = 'GATK_metrics/{sample}__{chr}.recal_data.table2'
	output:
		'GATK_metrics/{sample}__{chr}.BQSRplots.pdf'
	threads: 2
	shell:
		"""
		module load {config[gatk_version]}
		GATK -p {threads} -m 8g AnalyzeCovariates \
			-R {config[ref_genome]} \
			-before {input.one} \
			-after {input.two} \
			-plots {output}
		"""

rule gatk_haplotype_caller:
# call gvcf
	input:
		bam = 'bam/chr_split/{sample}/{sample}__{chr}.realigned.CleanSam.sorted.markDup.gatk_realigner.recalibrated.bam',
		bqsr = 'GATK_metrics/{sample}__{chr}.recal_data.table1'
	output:
		temp('gvcfs/chr_split/{sample}/{sample}__{chr}.g.vcf.gz')
	threads: 2
	shell:
		"""
		module load {config[gatk_version]}
		GATK -p {threads} -m 8g HaplotypeCaller \
			-R {config[ref_genome]} \
			-I {input.bam} \
			--emitRefConfidence GVCF \
			-BQSR {input.bqsr} \
			-o {output}
		"""

rule picard_merge_bams:
# merge chr split bams into one bam per sample
	input:
		chr_bam_to_single_bam
	output:
		'bam/{sample}.realigned.recalibrated.bam'
	threads: 2
	shell:
		"""
		module load {config[picard_version]}
		cat_inputs_i=""
		for bam in {input}; do
			cat_inputs_i+="I=$bam "; done
		java -Xmx15g -XX:+UseG1GC -XX:ParallelGCThreads={threads} -jar $PICARD_JAR \
			MergeSamFiles \
			$cat_inputs_i \
			O={output}
		"""

rule picard_merge_gvcfs:
# merge chr split gvcf back into one gvcf per sample
	input:
		chr_GVCF_to_single_GVCF
	output:
		'gvcfs/{sample}.g.vcf.gz'
	threads: 2
	shell:
		"""
		module load {config[picard_version]}
		cat_inputs_i=""
		for gvcf in {input}; do
			cat_inputs_i+="I=$gvcf "; done
		java -Xmx15g -XX:+UseG1GC -XX:ParallelGCThreads={threads} -jar $PICARD_JAR \
			MergeVcfs \
			$cat_inputs_i \
			O={output}
		"""

rule multiqc_gatk:
# run multiqc on recalibrator metrics
	input:
		expand('GATK_metrics/{sample}__{chr}.recal_data.table1',sample=SAMPLES, chr=CHRS),
		expand('GATK_metrics/{sample}__{chr}.recal_data.table2', sample=SAMPLES, chr=CHRS)
	output:
		'GATK_metrics/multiqc_report'
	shell:
		"""
		module load multiqc
		multiqc -f -o {output} GATK_metrics
		"""

rule multiqc_fastqc:
	input:
		expand('fastqc/{sample}', sample=SAMPLES)
	output:
		fastqc = 'fastqc/multiqc_report'
	shell:
		"""
		module load multiqc
		multiqc -f -o {output} fastqc/
		"""

